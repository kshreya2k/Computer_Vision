{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":30378,"sourceType":"datasetVersion","datasetId":23777}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\n## Image Classification using Fine-Tuned VGG16 Model - Cats and Dogs Image Classification with 99% accuracy(approx.)\n\nThis notebook demonstrates the process of building an image classification model using transfer learning with a fine-tuned VGG16 convolutional neural network (CNN). The objective is to classify images of cats and dogs. The dataset used for this task consists of images from the \"Cats and Dogs\" dataset.\n\n1. **Import Libraries**: Import necessary libraries for data preprocessing, model building, and evaluation.\n2. **Load Dataset**: Load and preprocess the dataset, which includes splitting it into training, validation, and testing sets.\n3. **Creating Sample Data**: Create sample data for training, validation, and testing by copying a subset of images from the original dataset.\n4. **Data Preparation**: Prepare the data for model training by defining image size, batch size, and creating data generators.\n5. **Build Fine-Tuned VGG16 Model**: Download the pre-trained VGG16 model and build a new sequential model by adding layers from the pre-trained model.\n6. **Model Compilation**: Compile the model with appropriate optimizer, loss function, and metrics.\n7. **Model Training**: Train the model using the training and validation datasets.\n8. **Model Evaluation**: Evaluate the model's performance on the test dataset by predicting classes and calculating accuracy.\n9. **Conclusion**: Summarize the results and discuss potential improvements or further steps.\n\nThis notebook provides a step-by-step guide to building and evaluating an image classification model for the Cats and Dogs dataset using transfer learning with VGG16. Let's get started!\n","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import warnings\n\nwarnings.simplefilter(action ='ignore', category=FutureWarning)\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\nimport shutil\nimport random\nimport glob\nimport itertools\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-03-12T01:09:22.441927Z","iopub.execute_input":"2024-03-12T01:09:22.443002Z","iopub.status.idle":"2024-03-12T01:09:22.452122Z","shell.execute_reply.started":"2024-03-12T01:09:22.442965Z","shell.execute_reply":"2024-03-12T01:09:22.451067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"# Define the path to the test directory\ntrain_dir_main = '/kaggle/input/cat-and-dog/training_set/training_set/'\ntest_dir_main = '/kaggle/input/cat-and-dog/test_set/test_set/'\n\n# Count files in subdirectories\ndef count_images_in_folders(directory):\n    folders = os.listdir(directory)\n    for folder in folders:\n        folder_path = os.path.join(directory, folder)\n        if os.path.isdir(folder_path):\n            images_count = len(os.listdir(folder_path))\n            print(f\"Folder: {folder}, Images Count: {images_count}\")\n\n# Print files in subdirectories\nprint(\"Train Set:\")\ncount_images_in_folders(train_dir_main)\n\nprint(\"\\nTest Set:\")\ncount_images_in_folders(test_dir_main)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:12:06.694472Z","iopub.execute_input":"2024-03-12T00:12:06.695592Z","iopub.status.idle":"2024-03-12T00:12:06.718770Z","shell.execute_reply.started":"2024-03-12T00:12:06.695559Z","shell.execute_reply":"2024-03-12T00:12:06.717635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Sample Data","metadata":{}},{"cell_type":"code","source":"# Define destination directories\ntrain_dir = \"/kaggle/working/training_set\"\nvalid_dir = \"/kaggle/working/validation_set\"\ntest_dir = \"/kaggle/working/test_set\"\n\n# Create validation directory if it does not exist\nos.makedirs(valid_dir, exist_ok=True)\n\n# Function to copy files\ndef copy_files(src_dir, dst_dir, category, num_files):\n    os.makedirs(os.path.join(dst_dir, category), exist_ok=True)\n    files = os.listdir(os.path.join(src_dir, category))\n    num_files_to_copy = min(num_files, len(files))\n    files_to_copy = files[:num_files_to_copy]\n    for file in files_to_copy:\n        src_path = os.path.join(src_dir, category, file)\n        dst_path = os.path.join(dst_dir, category, file)\n        shutil.copy(src_path, dst_path)\n\n# Copy 1000 cats and dogs from the train set to the training directory\ncopy_files(train_dir_main, train_dir, 'cats', 500)\ncopy_files(train_dir_main, train_dir, 'dogs', 500)\n\n# Copy 500 cats and dogs from the test set to the test directory\ncopy_files(test_dir_main, test_dir, 'cats', 250)\ncopy_files(test_dir_main, test_dir, 'dogs', 250)\n\n# Copy 500 cats and 500 dogs from the test set to the validation directory\ncopy_files(test_dir_main, valid_dir, 'cats', 250)\ncopy_files(test_dir_main, valid_dir, 'dogs', 250)\n\n# Print files in directories\nprint(\"Train Directory:\")\ncount_images_in_folders(train_dir)\nprint(\"\\nTest Directory:\")\ncount_images_in_folders(test_dir)\nprint(\"\\nValidation Directory:\")\ncount_images_in_folders(valid_dir)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:12:18.097747Z","iopub.execute_input":"2024-03-12T00:12:18.098136Z","iopub.status.idle":"2024-03-12T00:12:24.625151Z","shell.execute_reply.started":"2024-03-12T00:12:18.098108Z","shell.execute_reply":"2024-03-12T00:12:24.623873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{"_kg_hide-output":true}},{"cell_type":"code","source":"# Define the image size and batch size\nimage_size = (224, 224)\nbatch_size = 10\n\n# Create an ImageDataGenerator for preprocessing\ndatagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n\n# Create the train_batches using flow_from_directory\ntrain_batches = datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    classes=['cats', 'dogs']\n)\n\n# Create the test_batches using flow_from_directory\ntest_batches = datagen.flow_from_directory(\n    test_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    classes=['cats', 'dogs']\n)\n\n# Create the valid_batches using flow_from_directory\nvalid_batches = datagen.flow_from_directory(\n    valid_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    classes=['cats', 'dogs']\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:12:42.448166Z","iopub.execute_input":"2024-03-12T00:12:42.448572Z","iopub.status.idle":"2024-03-12T00:12:42.509061Z","shell.execute_reply.started":"2024-03-12T00:12:42.448543Z","shell.execute_reply":"2024-03-12T00:12:42.508086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_total_images = len(train_batches.filenames)\nvalid_total_images = len(valid_batches.filenames)\ntest_total_images = len(test_batches.filenames)\n\nprint(f\"Total Train Images: {train_total_images}, Total Valid Images: {valid_total_images}, Total Test Images: {test_total_images}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:12:47.842882Z","iopub.execute_input":"2024-03-12T00:12:47.843280Z","iopub.status.idle":"2024-03-12T00:12:47.849232Z","shell.execute_reply.started":"2024-03-12T00:12:47.843250Z","shell.execute_reply":"2024-03-12T00:12:47.848314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert train_batches.n == 1000\nassert test_batches.n == 499\nassert valid_batches.n == 499\nassert train_batches.num_classes == test_batches.num_classes == valid_batches.num_classes == 2","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:12.524281Z","iopub.execute_input":"2024-03-12T00:13:12.524660Z","iopub.status.idle":"2024-03-12T00:13:12.530944Z","shell.execute_reply.started":"2024-03-12T00:13:12.524633Z","shell.execute_reply":"2024-03-12T00:13:12.529585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs, labels = next(train_batches)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:14.940479Z","iopub.execute_input":"2024-03-12T00:13:14.940923Z","iopub.status.idle":"2024-03-12T00:13:14.987969Z","shell.execute_reply.started":"2024-03-12T00:13:14.940888Z","shell.execute_reply":"2024-03-12T00:13:14.986844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"# Create plot function\ndef plotImages(images_arr) :\n    fig, axes = plt.subplots(1, 10, figsize = (20,20))\n    axes = axes. flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n    \n# Print images & labels\nplotImages(imgs)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:17.385555Z","iopub.execute_input":"2024-03-12T00:13:17.386230Z","iopub.status.idle":"2024-03-12T00:13:18.016609Z","shell.execute_reply.started":"2024-03-12T00:13:17.386196Z","shell.execute_reply":"2024-03-12T00:13:18.015271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Fine-Tuned Vgg16 Model","metadata":{}},{"cell_type":"code","source":"# Download model from \"https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16\"\nvgg16_model = tf.keras.applications.vgg16.VGG16()","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:25.511694Z","iopub.execute_input":"2024-03-12T00:13:25.512116Z","iopub.status.idle":"2024-03-12T00:13:43.306341Z","shell.execute_reply.started":"2024-03-12T00:13:25.512084Z","shell.execute_reply":"2024-03-12T00:13:43.305150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vgg16 Model Summary","metadata":{}},{"cell_type":"code","source":"# Print model structure\nvgg16_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:48.737246Z","iopub.execute_input":"2024-03-12T00:13:48.738337Z","iopub.status.idle":"2024-03-12T00:13:48.779033Z","shell.execute_reply.started":"2024-03-12T00:13:48.738298Z","shell.execute_reply":"2024-03-12T00:13:48.777852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create function for count_params\ndef count_params(model):\n    \"\"\"Count the total number of trainable and non-trainable parameters in the model.\"\"\"\n    non_trainable_params = sum(v.shape.num_elements() for v in model.non_trainable_weights)\n    trainable_params = sum(v.shape.num_elements() for v in model.trainable_weights)\n    return {'non_trainable_params': non_trainable_params, 'trainable_params': trainable_params}\n\n# Call the function to get the counts\nparams = count_params(vgg16_model)\n\n# Print the counts\nprint(\"Total trainable parameters:\", params['trainable_params'])\nprint(\"Total non-trainable parameters:\", params['non_trainable_params'])","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:53.839422Z","iopub.execute_input":"2024-03-12T00:13:53.839810Z","iopub.status.idle":"2024-03-12T00:13:53.847844Z","shell.execute_reply.started":"2024-03-12T00:13:53.839780Z","shell.execute_reply":"2024-03-12T00:13:53.846641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the function to get the counts\nparams = count_params(vgg16_model)\n\n# Check the counts\nassert params['non_trainable_params'] == 0\nassert params['trainable_params'] == 138357544","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:56.720074Z","iopub.execute_input":"2024-03-12T00:13:56.721157Z","iopub.status.idle":"2024-03-12T00:13:56.727362Z","shell.execute_reply.started":"2024-03-12T00:13:56.721114Z","shell.execute_reply":"2024-03-12T00:13:56.725887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Sequential Model from Vgg16 Model","metadata":{}},{"cell_type":"code","source":"# Create a new Sequential model\nmodel = Sequential()\n\n# Add layers from the VGG16 model to the new Sequential model\nfor layer in vgg16_model.layers[:-1]:\n    model.add(layer)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:13:59.206251Z","iopub.execute_input":"2024-03-12T00:13:59.207318Z","iopub.status.idle":"2024-03-12T00:13:59.415877Z","shell.execute_reply.started":"2024-03-12T00:13:59.207284Z","shell.execute_reply":"2024-03-12T00:13:59.414664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Print new Sequential Model Summary","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:03.718195Z","iopub.execute_input":"2024-03-12T00:14:03.719400Z","iopub.status.idle":"2024-03-12T00:14:03.761064Z","shell.execute_reply.started":"2024-03-12T00:14:03.719354Z","shell.execute_reply":"2024-03-12T00:14:03.759937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the function to get the counts\nparams = count_params(model)\n\n# Check the counts\nassert params['non_trainable_params'] == 0\nassert params['trainable_params'] == 134260544","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:09.615025Z","iopub.execute_input":"2024-03-12T00:14:09.615419Z","iopub.status.idle":"2024-03-12T00:14:09.620662Z","shell.execute_reply.started":"2024-03-12T00:14:09.615388Z","shell.execute_reply":"2024-03-12T00:14:09.619894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze all layers in the model\nfor layer in model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:14.101556Z","iopub.execute_input":"2024-03-12T00:14:14.101959Z","iopub.status.idle":"2024-03-12T00:14:14.107377Z","shell.execute_reply.started":"2024-03-12T00:14:14.101929Z","shell.execute_reply":"2024-03-12T00:14:14.106116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding ouput layer with softmax activation function\nmodel.add(Dense(units=2, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:18.171403Z","iopub.execute_input":"2024-03-12T00:14:18.171806Z","iopub.status.idle":"2024-03-12T00:14:18.203332Z","shell.execute_reply.started":"2024-03-12T00:14:18.171766Z","shell.execute_reply":"2024-03-12T00:14:18.202208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:21.409954Z","iopub.execute_input":"2024-03-12T00:14:21.410345Z","iopub.status.idle":"2024-03-12T00:14:21.455568Z","shell.execute_reply.started":"2024-03-12T00:14:21.410313Z","shell.execute_reply":"2024-03-12T00:14:21.454381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the function to get the counts\nparams = count_params(model)\n\n# Check the new counts\nassert params['trainable_params'] == 8194\nassert params['non_trainable_params'] == 134260544","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:24.726900Z","iopub.execute_input":"2024-03-12T00:14:24.727261Z","iopub.status.idle":"2024-03-12T00:14:24.732701Z","shell.execute_reply.started":"2024-03-12T00:14:24.727236Z","shell.execute_reply":"2024-03-12T00:14:24.731655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compile the Fine-Tuned Vgg16 model","metadata":{}},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:27.811168Z","iopub.execute_input":"2024-03-12T00:14:27.811552Z","iopub.status.idle":"2024-03-12T00:14:27.828881Z","shell.execute_reply.started":"2024-03-12T00:14:27.811524Z","shell.execute_reply":"2024-03-12T00:14:27.827646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Fine-Tuned Vgg16 model","metadata":{}},{"cell_type":"code","source":"# Train the model\nmodel.fit(x=train_batches, validation_data=valid_batches, epochs=5, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:14:31.446303Z","iopub.execute_input":"2024-03-12T00:14:31.446688Z","iopub.status.idle":"2024-03-12T00:45:45.439243Z","shell.execute_reply.started":"2024-03-12T00:14:31.446660Z","shell.execute_reply":"2024-03-12T00:45:45.438172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if accuracy exceeds 95%\nassert max(model.history.history['accuracy']) > 0.95","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:48:00.536954Z","iopub.execute_input":"2024-03-12T00:48:00.537368Z","iopub.status.idle":"2024-03-12T00:48:00.542147Z","shell.execute_reply.started":"2024-03-12T00:48:00.537334Z","shell.execute_reply":"2024-03-12T00:48:00.540891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on test batches","metadata":{}},{"cell_type":"code","source":"# Predict using the model\npredictions = model.predict(x = test_batches, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:51:22.056410Z","iopub.execute_input":"2024-03-12T00:51:22.056813Z","iopub.status.idle":"2024-03-12T00:53:25.461528Z","shell.execute_reply.started":"2024-03-12T00:51:22.056784Z","shell.execute_reply":"2024-03-12T00:53:25.460485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate confusion matrix\ncm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:55:49.696431Z","iopub.execute_input":"2024-03-12T00:55:49.696801Z","iopub.status.idle":"2024-03-12T00:55:49.705507Z","shell.execute_reply.started":"2024-03-12T00:55:49.696774Z","shell.execute_reply":"2024-03-12T00:55:49.704405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing classes and labels\ntest_batches.class_indices","metadata":{"execution":{"iopub.status.busy":"2024-03-12T00:59:39.415315Z","iopub.execute_input":"2024-03-12T00:59:39.415677Z","iopub.status.idle":"2024-03-12T00:59:39.422721Z","shell.execute_reply.started":"2024-03-12T00:59:39.415650Z","shell.execute_reply":"2024-03-12T00:59:39.421530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Metrics for evaluation","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"blue\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \ncm_plot_labels = ['cats', 'dogs']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix', cmap=plt.cm.Greens)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T01:07:09.186648Z","iopub.execute_input":"2024-03-12T01:07:09.187710Z","iopub.status.idle":"2024-03-12T01:07:09.486150Z","shell.execute_reply.started":"2024-03-12T01:07:09.187677Z","shell.execute_reply":"2024-03-12T01:07:09.485313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate predicted classes\npredicted_classes = np.argmax(predictions, axis=-1)\n\n# Calculate accuracy\naccuracy = accuracy_score(test_batches.classes, predicted_classes)\n\nprint(\"Accuracy on test dataset:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T01:09:44.456713Z","iopub.execute_input":"2024-03-12T01:09:44.457446Z","iopub.status.idle":"2024-03-12T01:09:44.464303Z","shell.execute_reply.started":"2024-03-12T01:09:44.457413Z","shell.execute_reply":"2024-03-12T01:09:44.463242Z"},"trusted":true},"execution_count":null,"outputs":[]}]}